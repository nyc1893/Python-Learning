
import numpy as np
import pandas as pd
from pandas import DataFrame



df=pd.read_csv('GE_kW_2009.csv')
df.shape
#is nan?

df=df.fillna(0)
#is zero?
df[df<0]=0
#df.to_csv('cici.csv')

 #in order to get the sum of wind turbines
dw=df.ix[list(range(0,52560)),list(range(6,59))] #maybe change cause the start CSV file
dw['ColSum']=dw.apply(lambda x:x.sum(),axis=1)  


dd=pd.read_csv('MET_2009.csv')
dd.isnull().sum()
dd=dd.fillna(0)
#dd[dd<0]=0
#dd.to_csv('cici2.csv')


#take out too much time item
#dd.ix[list(range(0,52560)),list(range(5,17))].head()

dd=dd.ix[list(range(0,52560)),list(range(5,17))]
dd.keys()


dt=pd.read_csv('GE_kW_2010.csv')

dt=dt.fillna(0)
#is zero?
dt[dt<0]=0
#dt.to_csv('cici2.csv')
dt.ix[list(range(0,52560)),list(range(5,58))].head()
dt=dt.ix[list(range(0,52560)),list(range(5,58))]
dt['ColSum']=dt.apply(lambda x:x.sum(),axis=1)  


dk=pd.read_csv('MET_2010.csv')
dk=dk.fillna(0)
#dk[dk<0]=0
dk=dk.ix[list(range(0,52560)),list(range(5,17))]


import matplotlib.pyplot as plt
import numpy as np
from sklearn import datasets, linear_model
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt


X_train = dd
X_test = dk

y_train=dw['ColSum']
y_real=dt['ColSum']

regr = linear_model.LinearRegression()
regr.fit(X_train, y_train)
y_pred = regr.predict(X_test)

c1=pd.DataFrame(y_pred,columns=['y_pred'])# numpuy.array to DataFrame
c2=pd.DataFrame(y_real)
c1.head()
c2.head()
c3=pd.concat([c1, c2], axis=1)

plt.figure(); 
c3.plot();
plt.show(); 

from sklearn.metrics import mean_squared_error
RMSE = mean_squared_error(y_real, y_pred)**0.5 #get the RMSE




from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestRegressor

max_features = [.1, .2,.3,.4, .5, .7, .9 ]
test_scores = []
for max_feat in max_features:
    clf = RandomForestRegressor(n_estimators=200, max_features=max_feat)
    test_score = np.sqrt(-cross_val_score(clf, X_train, y_train, cv=5, scoring='neg_mean_squared_error'))
    test_scores.append(np.mean(test_score))

plt.plot(max_features, test_scores)
plt.title("Max Features vs CV Error");
plt.show()


rf = RandomForestRegressor(n_estimators=500, max_features=.3)
rf.fit(X_train, y_train)
y_rf = rf.predict(X_test)
RMSE_RF = mean_squared_error(y_real, y_rf)**0.5 #get the RMSE


"""


import matplotlib.pyplot as plt  
import numpy as np  
import scipy as sp  
from scipy.stats import norm  
from sklearn.pipeline import Pipeline  
from sklearn.linear_model import LinearRegression  
from sklearn.preprocessing import PolynomialFeatures  
from sklearn import linear_model  

def rmse(y_test, y):  
    return sp.sqrt(sp.mean((y_test - y) ** 2)) 


def nse(y_test, y):  
    return 1-((sp.mean(y - y_test)/sp.mean(y -sp.mean(y))) ** 2)

def ccd(y_test, y):  
    k1=(sp.mean((y_test - y)*(y_test-sp.mean(y_test))))**2
    k2=sp.mean((y_test-sp.mean(y_test))**2)
    k3=sp.mean((y-sp.mean(y))**2)
    return k1/(k2*k3)

def pbias(y_test, y):  

    return sp/mean()

y_real.iloc[list(range(0,5))]
"""













